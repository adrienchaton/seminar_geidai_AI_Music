<!---
render and export with https://md2pdf.netlify.com (https://www.markdowntopdf.com does not support japanese characters)
--->

## Japanese abstracts of the 2nd Seminar on Artificial Intelligence applied to Sound and Music Composition

**後藤英:** ディープ・ラーニングを用いた現代音楽の作曲技法

これはAIをステージで用いながらの演奏ではなく、ディープ・ラーニングを用いて作曲し、楽器の演奏者に演奏をしてもらう例である。このために、以下の問題を提起することができる。ディープ・ラーニングは作曲の進歩に何らかの影響を及ばしてくれているのだろうか？ 作曲家の立場で、あくまでも音楽の発展のためにAIがどのような使われ方をすべきか? 純粋に、音楽のみのためにディープ・ラーニングを用いてどのような新たなアイデアを見つけて作曲できるか？ むしろ新たなアイデアに結びつけることができるか？AIの一部として語られているアルゴリズムも、それを用いて、これまでのアルゴリズミック・コンポジションを本当の意味で超えられるのだろうか？ これらはいずれもディープ・ラーニングを用いて何らかの形で芸術の発展を試みることが主眼となっている。

**満潔:** Max/MSPのbachライブラリーについて

Max/MSPの中のbachライブラリーは、コンピューター支援作曲とリアルタイム環境、この二つの要素を強く結びつけた便利なツールである。今回は、bachライブラリーに関する使用方法と実用例について説明を行う。

**姜信愛:** 人工知能技術を用いた芸術作品の紹介と研究の動向について

ー最近の人工知能(AI)を利活用した芸術作品を紹介しつつ、今後、人工知能(AI)の利活用が拡がっていく可能性について話す。

**Jinwoong Kim:** Orchidea、インテリジェント補助オーケストレーションツール

IRCAMで開発されたオーケストレーション補助ツール"オルキディア"について話す。オーキディアの概念と、オーキディアが使用する人工知能の技術を紹介する。

**谷原佐智:** AI作曲と身体性　〜作曲するバーチャルシンガーから世界のAI作曲ロボットまで〜

現在、人工知能のほとんどは身体性を持っていない。AI作曲においても、作曲家の頭脳を人工的に置き換えたものが大半である。
しかし昨今、作曲する知能と身体の両者を備えた「AI音楽身体エージェント」とでも呼べる研究が世界で進展しつつある。
そこで、「AI作曲と身体性」と題し、世界のAI作曲演奏ロボットなど、作曲する知能と身体とを結ぶ人工知能の可能性についてお話ししたい。

**Philippe Esling:** ACIDS-人工創造知能

IRCAMの人工創造知能とデータサイエンス（ACIDS）チームは、オーディオミクスチャーの特性に的を当てて音楽の創造性をモデル化しようとしており、音楽情報の多様性を理解して制御するために、記号（スコア）とシグナル（オーディオ）の表現の間にある横断領域を研究している。数学的な確率による創造性モデルの枠組みを紹介したあとは、多様なオーディオバリエーションの要素をどう扱って解くのかという問いについてディスカッションをしたい。音の位相空間を移動させ、音波形とスコアを操作させ、自分たちの声を用いてオーディオシンセサイザーを制御させてチームで作ったモデルと音楽作品について、幾つか詳しく説明する。

**Daisuke Saito:** 合唱音声信号処理に向けて --ソースフィルタモデルによるアプローチ--

本発表では信号処理アプローチによる合唱音声のモデリングについて論じる。音声合成の品質は近年の深層学習技術の発展に伴って飛躍的に向上した。特にWaveNetに代表される波形のサンプル点を直接モデル化する手法により単一発声者に関しては自然音声と遜色のない音声が合成可能となった。一方で複数歌唱者の同時発声をモデル化するためには、発声者間の調和性など複数発声独自の要素 を考慮する必要がある。本発表ではソースフィルタモデルを出発点として現在我々が進めている合唱音声のモデリングについて紹介する。

**Naotake Masuda:** 深層生成モデルとNormalizing Flowsによるシンセサイザーの制御

シンセサイザーは現代の音楽制作において欠かせないツールとなっている。一方で、シンセサイザーはパラメータが多く、パラメータ間の関係も複雑である。そのため、シンセサイザーのによって思い通りの音を出すことは困難である。本研究ではより効率的にパラメータの推定を行い、直感的なシンセサイザーの操作を可能にする、変分オートエンコーダ(VAE)ベースのモデルを提案する。最後に、複数のVSTシンセサイザーの制御についての結果を示し、様々なシンセサイザーのモデリングにおける課題について論じる。

**Adrien Bitton:** 生波形生成のためのニューラルグラニュラーサウンド合成。

グラニュラーシンセシスは、サウンドシンセシスに広く使用されている手法である。その基礎となる概念は生成ニューラルネットワークに関連しており、実装でき且つこの手法にある従来の技術的限界を扱っている。機械学習のコミュニティではまだ研究されていない、生波形生成の研究方法である。この領域に適したVariation Auto-Encoderモデルを紹介し、その構成部分の解釈可能性について話し合い、音符およびドラム生成、テクスチャー合成、非音楽オーディオ生成の実験について報告する。
