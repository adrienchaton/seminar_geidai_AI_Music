In collaboration with:

* The University of Tokyo

* IRCAM (Paris, France - Institut de Recherche et Coordination Acoustique/Musique).

&nbsp;


<p align="center"> <img src="https://raw.githubusercontent.com/adrienchaton/seminar_geidai_AI_Music/master/misc/Mandelbrot.jpeg" width="533" height="400"> </p>

&nbsp;


## Outline

Machine learning and deep neural networks have thrived through the last decades on increasing computational ressources, allowing for a steady development of new concepts along with a broad range of applications extending and complementing human knowledge. Computer vision and text processing are prominent topics in which many algorithms have been tested. They generalize to a certain extent to music language and sound, which nonetheless hold some key specificities that have themselves established as new reference topics to AI research.

The knowledge and experience of music are grounded into several layers of information. In the symbolic domain, one can account for compositional structures. However it is abstracted from the sound content and thus unmatched with a range of contemporary practices and performances that focus on sound production and perception. Forming and analysing consistent sctrutures accross scales ranging from streams of waveform samples (~ miliseconds) to musical events and pieces (seconds to minutes) has drawn many research efforts to close a gap, that is still open.

To address these questions, a constant dialogue has florished accross modalities. Pulling from general to music oriented developements and back. Successfully specifying some of these breakthroughs to sound domain and raising new challenges along with solutions that directly emerged from the intrinsic nature of sound. Be it on the level of music theory and signal processing, or to their resulting psychoacoustic qualities.

Given this extensive corpus of research and technologies, that is constantly refining, remains yet a challenge in implementing meaningful interactions for human creativity and production, such as applying to music composition and sound design. How will generative neural networks integrate in our practices ? How can AI enrich human art and foster new paradigms for music ?

This pannel of presentations followed with Q&A is an invitation to assess some of the latest developments of AI applied to music and sound, both from a computational and a composer view. Engaging computer science and music practitioners to discuss the specific potentialities that are arising at the interesection of their fields and beyond.

## Program

Titles, abstracts and schedule of the program are being prepared.

**16h30:** Welcome coffee

**17h-22h:** Presentations and Q&A with:

* Suguru Goto (Tokyo University of the Arts)

*The Technique of Contemporary Music Composition with using Deep Learning*

* Jie Man (Tokyo University of the Arts): *Introduction of bach library in Max/MSP*
* Shinae Kang (Tokyo University of the Arts): *A discussion of works created with the aid of AI and AI research trends for music*
* Jinwoong Kim (Tokyo University of the Arts): *Orchidea, An intelligent assisted orchestration tool*
* Sachi Ihara (Tokyo University of the Arts): *AI composition and physicality --from Virtual Composer-Singer to Music Robots all over the world--*
* Philippe Esling (IRCAM): *Modeling musical creativity with variational inference and probabilistic generative models*
* Daisuke Saito (The University of Tokyo): *Modeling vocals in music*
* Naotake Masuda (The University of Tokyo): *FlowSynth model for parameter inference and meta/semantic control of digital synthesizers (VST)*
* Adrien Bitton (IRCAM/The University of Tokyo): *Neural granular sound synthesis for raw waveform generation*

[English program (under preparation)](https://drive.google.com/file/d/1ioBLOwZ5pccOKJCbBVE54J64o1aA2CiB/view?usp=sharing)

[Japanese program (under preparation)](https://drive.google.com/file/d/1N6GI9itQTu5kZH7UKyq5WbXBqB7xdd7l/view?usp=sharing)

[Presentation materials](https://github.com/adrienchaton/seminar_geidai_AI_Music/tree/master/documents) will be provided prior to the start of the seminar.

## Details

**Date and time:** The 15th of January 2020, from 16h30 until 22h. <ins>Start of the first presentation at 17h</ins>.

**Place:** Tokyo University of the Arts, Department of Musical Creativity and the Environment, <ins>Senju Campus</ins>, The 1st conference room

〒 120-0034, 1-25-1 Senju, Adachi-ku, Tokyo.

[Access to Senju Campus](https://www.geidai.ac.jp/english/access#SenjuCampus)

Presentations will be given in English, however, Q&A may be possible in Japanese. We invite the discussions to be continued around a table in a neighboring Izakaya after 22h.

Following this seminar, a concert is being prepared for Februar by the Department of Musical Creativity and will be announced.

For information about the previous edition, please refer to the [1st edition webpage](https://tcmml.github.io).

**Contacts:** bitton@ircam.fr / goto.suguru@ms.geidai.ac.jp


<!---
The program of this seminar is being prepared and will be announced in the beginning of December.

It is a collaboration between:

* Tokyo University of the Arts (Geidai)

* The University of Tokyo (Todai)

* IRCAM (Paris, France - Institut de Recherche et Coordination Acoustique/Musique)

contact: bitton@ircam.fr

For information about the previous edition, please refer to the [1st edition webpage](https://tcmml.github.io)
-->

<!---

![Image](https://raw.githubusercontent.com/adrienchaton/seminar_geidai_AI_Music/master/misc/xmm_featured.jpg)

## Welcome to GitHub Pages

You can use the [editor on GitHub](https://github.com/adrienchaton/seminar_geidai_AI_Music/edit/master/README.md) to maintain and preview the content for your website in Markdown files.

Whenever you commit to this repository, GitHub Pages will run [Jekyll](https://jekyllrb.com/) to rebuild the pages in your site, from the content in your Markdown files.

### Markdown

Markdown is a lightweight and easy-to-use syntax for styling your writing. It includes conventions for

```markdown
Syntax highlighted code block

# Header 1
## Header 2
### Header 3

- Bulleted
- List

1. Numbered
2. List

**Bold** and _Italic_ and `Code` text

[Link](url) and ![Image](src)
```

For more details see [GitHub Flavored Markdown](https://guides.github.com/features/mastering-markdown/).

### Jekyll Themes

Your Pages site will use the layout and styles from the Jekyll theme you have selected in your [repository settings](https://github.com/adrienchaton/seminar_geidai_AI_Music/settings). The name of this theme is saved in the Jekyll `_config.yml` configuration file.

### Support or Contact

Having trouble with Pages? Check out our [documentation](https://help.github.com/categories/github-pages-basics/) or [contact support](https://github.com/contact) and we’ll help you sort it out.

-->

